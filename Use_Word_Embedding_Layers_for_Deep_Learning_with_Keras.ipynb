{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Use Word Embedding Layers for Deep Learning with Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptsurko/AIML-notebooks/blob/master/Use_Word_Embedding_Layers_for_Deep_Learning_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37YzRNyVTdyt",
        "colab_type": "code",
        "outputId": "83bcec4d-8b33-4899-ac22-fe6c64f0bdf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "np.random.seed(1337)\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "# https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OECmRWG7TzlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define documents\n",
        "docs = ['Well done!',\n",
        "\t\t'Good work',\n",
        "\t\t'Great effort',\n",
        "\t\t'nice work',\n",
        "\t\t'Excellent!',\n",
        "\t\t'Weak',\n",
        "\t\t'Poor effort!',\n",
        "\t\t'not good',\n",
        "\t\t'poor work',\n",
        "\t\t'Could have done better.']\n",
        "# define class labels\n",
        "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8T0exwPT5kR",
        "colab_type": "code",
        "outputId": "800d3d29-8ef5-42aa-c935-4f239e3f1add",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "tokenizer = Tokenizer(num_words=50, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(docs)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size=len(word_index) + 1\n",
        "words = list(tokenizer.word_index.keys())[1:]\n",
        "\n",
        "encoded_docs = tokenizer.texts_to_sequences(docs)\n",
        "\n",
        "print('word_index: ', str(word_index))\n",
        "print('len(word_index): ', len(word_index))\n",
        "print('vocab_size: ', vocab_size)\n",
        "print('words: ', words)\n",
        "print(encoded_docs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word_index:  {'<OOV>': 1, 'work': 2, 'done': 3, 'good': 4, 'effort': 5, 'poor': 6, 'well': 7, 'great': 8, 'nice': 9, 'excellent': 10, 'weak': 11, 'not': 12, 'could': 13, 'have': 14, 'better': 15}\n",
            "len(word_index):  15\n",
            "vocab_size:  16\n",
            "words:  ['work', 'done', 'good', 'effort', 'poor', 'well', 'great', 'nice', 'excellent', 'weak', 'not', 'could', 'have', 'better']\n",
            "[[7, 3], [4, 2], [8, 5], [9, 2], [10], [11], [6, 5], [12, 4], [6, 2], [13, 14, 3, 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XvRqcfGUDjZ",
        "colab_type": "code",
        "outputId": "402bac54-a56b-4fc0-fe45-1a153d70c2f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "source": [
        "# pad documents to a max length of 4 words\n",
        "max_length = 4\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 7  3  0  0]\n",
            " [ 4  2  0  0]\n",
            " [ 8  5  0  0]\n",
            " [ 9  2  0  0]\n",
            " [10  0  0  0]\n",
            " [11  0  0  0]\n",
            " [ 6  5  0  0]\n",
            " [12  4  0  0]\n",
            " [ 6  2  0  0]\n",
            " [13 14  3 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHUlTMx_UFv8",
        "colab_type": "code",
        "outputId": "22fcf630-2284-49ae-bcb2-a6bf92da0cdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        }
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summarize the model\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(padded_docs, labels, epochs=50, verbose=0, shuffle=False)\n",
        "\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))\n",
        "\n",
        "embeddings = model.layers[0].get_weights()[0]\n",
        "print('embeddings.shape: ', embeddings.shape)\n",
        "print('embeddings: ', embeddings)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 4, 8)              128       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 161\n",
            "Trainable params: 161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Accuracy: 89.999998\n",
            "embeddings.shape:  (16, 8)\n",
            "embeddings:  [[ 0.05721183 -0.03809275 -0.00354055  0.05120752 -0.00139931  0.09407571\n",
            "  -0.04230647 -0.01367894]\n",
            " [ 0.03533186 -0.0128661  -0.02535462 -0.0490261  -0.00229315 -0.00074725\n",
            "  -0.00457001  0.03586162]\n",
            " [-0.07674701 -0.07548218  0.04792396  0.0756007  -0.01280425  0.06967522\n",
            "  -0.0931087   0.06812938]\n",
            " [-0.02533895 -0.02356108  0.09428222  0.01421347 -0.02425501  0.07276456\n",
            "   0.09030507  0.02613143]\n",
            " [ 0.09358136  0.0981415  -0.07656319 -0.04236201  0.06699132  0.07476337\n",
            "   0.04695722 -0.02696845]\n",
            " [ 0.03710543  0.03446155  0.02812333  0.00029047  0.05245783 -0.01447883\n",
            "   0.06642719 -0.04784231]\n",
            " [-0.0130614  -0.0994553   0.02397942 -0.06892115 -0.048596   -0.0383199\n",
            "  -0.00868113  0.03773278]\n",
            " [ 0.00421996  0.05851377 -0.00071551  0.02360978  0.03483599 -0.00053591\n",
            "   0.00671118 -0.03395209]\n",
            " [ 0.02855411  0.07973802 -0.06805081  0.04700932  0.00757733  0.09011093\n",
            "   0.00991242 -0.0266555 ]\n",
            " [ 0.04921665  0.05614909 -0.09593     0.01934704  0.09894146  0.01212154\n",
            "   0.08441664 -0.04181107]\n",
            " [ 0.08414063  0.05713241 -0.03400818  0.07512     0.08010426  0.05735081\n",
            "   0.03297949 -0.02308151]\n",
            " [-0.09383132 -0.01577899  0.07994239 -0.0528978  -0.06202623 -0.01368152\n",
            "  -0.04970567  0.0182632 ]\n",
            " [-0.07592899 -0.10597192  0.05086605 -0.07985432 -0.04873974 -0.00215527\n",
            "  -0.02941471  0.04300642]\n",
            " [-0.02632696 -0.01664725  0.04544517 -0.05771195 -0.04605148 -0.05137076\n",
            "  -0.01131513  0.08491674]\n",
            " [ 0.06173531  0.03028302 -0.09569035 -0.092835    0.04249402 -0.09959312\n",
            "   0.08972134 -0.0842324 ]\n",
            " [ 0.00317925  0.09743614 -0.05561393 -0.01214492 -0.05005974 -0.07531155\n",
            "   0.0534388   0.00042591]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSYM3k9U7Z7Y",
        "colab_type": "code",
        "outputId": "46b83e30-22ae-48c7-8b3c-c24569a502bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word1 = 'work'\n",
        "word2 = 'better'\n",
        "\n",
        "weight1 = embeddings[word_index[word1] - 1]\n",
        "weight2 = embeddings[word_index[word2] - 1]\n",
        "\n",
        "print('cosine distance between %s and %s = %s' % (word1, word2, cosine(weight1, weight2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cosine distance between work and better = 0.6851622462272644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8golHedIxEGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import io\n",
        "\n",
        "# out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "# out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "# for num, word in enumerate(words):\n",
        "#   vec = embeddings[num+1] # skip 0, it's padding.\n",
        "#   out_m.write(word + \"\\n\")\n",
        "#   out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "# out_v.close()\n",
        "# out_m.close()\n",
        "\n",
        "# # If you are running this tutorial in Colaboratory, you can use the following snippet to download these files to your local machine (or use the file browser, View -> Table of contents -> File browser).\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gIGCOl2zTds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try:\n",
        "#   from google.colab import files\n",
        "# except ImportError:\n",
        "#    pass\n",
        "# else:\n",
        "#   files.download('vecs.tsv')\n",
        "#   files.download('meta.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C69cY9oeXpBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}